<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Sync-NeRF</title>

    <meta name="description" content="Sync-NeRF: Generalizing Dynamic NeRFs to Unsynchronized Videos">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://seoha-kim.github.io/sync-nerf"/>
    <meta property="og:title" content="Sync-NeRF" />
    <meta property="og:description" content="Project page for Sync-NeRF: Generalizing Dynamic NeRFs to Unsynchronized Videos." />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Sync-NeRF" />
    <meta name="twitter:description" content="Project page for Sync-NeRF: Generalizing Dynamic NeRFs to Unsynchronized Videos." />

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üç∏</text></svg>">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>
    <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

	
	<link rel="stylesheet" href="css/dics.min.css">
    <script src="scripts/dics.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', domReady);
        function domReady() {
            for (const e of document.querySelectorAll(".b-dics")) {
                new Dics({
                    container: e,
                    textPosition: "top"
                });
            }
        }
    </script>
	
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>Sync-NeRF</b>: Generalizing Dynamic NeRFs 
                <br> to Unsynchronized Videos <br>
                <small>
                    ArXiv
                </small>
            </h2>
        </div>
		
		<div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <b>
                        Seoha Kim*
                        </b>
                        <br>Yonsei University
                    </li>
					<li>
                        <b>
                        Jeongmin Bae*
                        </b>
                        <br>Yonsei University
                    </li>
					<li>
                        <b>
                        Youngsik Yun
                        </b>
                        <br>Yonsei University
                    </li>
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <b>
                        Hahyun Lee
                        </b>
                        <br>ETRI
                    </li>
					<li>
                        <b>
                        Gun Bang
                        </b>
                        <br>ETRI
                    </li>
                    <li>
                        <b>
                        Youngjung Uh
                        </b>
                        <br>Yonsei University
                    </li> 				
                </ul>
            </div>
        </div>
		
		<div class="row">
            <div class="col-md-12 text-center">
                *Denotes equal contribution <br>
                <a href="https://vilab.yonsei.ac.kr/">Visual Intelligence Lab in Yonsei University</a><br>
            </div>
        </div>


        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="Sync_NeRF_Generalizing_Dynamic_NeRFs_to_Unsynchronized_Videos.pdf">
                            <image src="img/syncnerf_paper_image.png" height="120px"></image>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/seoha-kim/Sync-NeRF" target="_blank">
                            <image src="img/github.png" height="120px"></image>
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://yonsei-my.sharepoint.com/:f:/g/personal/hailey07_o365_yonsei_ac_kr/Er_SF3saB9JPp-uaj0W9NaABOZ0V7czk90yMp4UNybXvPg?e=EAxwOH">
                            <image src="img/dataset_fox.png" height="120px"></image>
                                <h4><strong>Dataset</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Teaser
                </h3>
                <video poster="" id="teaser" autoplay controls muted loop playsinline width="100%;">
                    <source src="videos/teaser.mp4"
                            type="video/mp4">
                </video><br>
                <p class="text-justify">
                    The commonly used Plenoptic Video Dataset in 4D scene reconstruction contains an unsynchronized video. If we include this view in the training set, baselines fail to reconstruct the motion around the unsynchronized viewpoint. In the same settings, our method significantly outperforms.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <!-- <image src="img/rays.jpg" class="img-responsive" alt="overview"><br> -->
                <p class="text-justify">
                    Recent advancements in 4D scene reconstruction using neural radiance fields (NeRF) have demonstrated the ability to represent dynamic scenes from multi-view videos. However, they fail to reconstruct the dynamic scenes and struggle to fit even the training views in unsynchronized settings. It happens because they employ a single latent embedding for a frame while the multi-view images at the frame were actually captured at different moments. To address this limitation, we introduce time offsets for individual unsynchronized videos and jointly optimize the offsets with NeRF. By design, our method is applicable for various baselines and improves them with large margins. Furthermore, finding the offsets naturally works as synchronizing the videos without manual effort. Experiments are conducted on the common Plenoptic Video Dataset and a newly built Unsynchronized Dynamic Blender Dataset to verify the performance and robustness of our method.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
                <video poster="" id="results" autoplay controls muted playsinline width="100%;">
                    <source src="videos/results.mp4"
                            type="video/mp4">
                </video><br>
                <p class="text-justify">
                    The above videos are rendered results from the Unsynchronized Plenoptic Video Dataset whose synchronization is perturbed on purpose.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method Overview
                </h3>
                <h4>
                    Problem Statement
                </h4>
                <br>
                <image src="img/problem.png" style="width:100%;" alt="problem statement"></image>
                <br>
                <p class="text-justify">
                    In an ideal situation, all multi-view images at specific frame captures the same moment of a scene. Under this assumption, each frame is represented by only one latent embedding. <br><br>

                    But video synchornization process requires manual efforts and even if the videos are assumed to be synchronized, there can be temporal mismatch within a frame.
                    Previous methods suffer from the discrepancy between the latent embedding of the frame and the actual status of the scene. <b>(b)</b> <br>
                    Comparably, <b>Sync-NeRF</b> resolves the temporal gap by introducing learnable time offsets $\delta$ for individual cameras.
                    It works as assigning correct temporal latent embeddings to unsynchronized videos, which is equivalent to synchronizing process by shifting.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h4>
                    Continuous temporal embedding
                </h4>
                <br>
                <image src="img/embedding.png" style="width:100%;" alt="continuous temporal embedding"></image>
                <br>
                <p class="text-justify">
                    <b>(a)</b> We present an implicit function-based approach for the methods utilizing per-frame temporal embeddings. We add time offset $\theta_{k}$ of camera $k$ to time input $t$. $T_{Œ∏}$ is the implicit function for mapping calibrated time into temporal embedding $z$. 
                    <b>(b)</b> We query the embedding at the calibrated time $t_{k}$ on grid-based models. Bilinear interpolation naturally allows continuous temporal embedding.
                </p>
            </div>
        </div>
	

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                The website template was borrowed from <a href="https://bakedsdf.github.io/">BakedSDF</a>.
                </p>
            </div>
        </div>

    </div>
</body>
</html>
